<p align="center">
    <img src="https://cdn-icons-png.flaticon.com/512/6295/6295417.png" align="center" width="30%">
</p>
<p align="center"><h1 align="center">ZENITH AI</h1></p>
<p align="center">
	<em><code>❯ Based on LLAMA-Index</code></em>
</p>
<p align="center">
	<img src="https://img.shields.io/github/license/heinerhardt/Llama-Index?style=flat&logo=opensourceinitiative&logoColor=white&color=6e8379" alt="license">
	<img src="https://img.shields.io/github/last-commit/heinerhardt/Llama-Index?style=flat&logo=git&logoColor=white&color=6e8379" alt="last-commit">
	<img src="https://img.shields.io/github/languages/top/heinerhardt/Llama-Index?style=flat&color=6e8379" alt="repo-top-language">
	<img src="https://img.shields.io/github/languages/count/heinerhardt/Llama-Index?style=flat&color=6e8379" alt="repo-language-count">
</p>
<p align="center">Built with the tools and technologies:</p>
<p align="center">
	<img src="https://img.shields.io/badge/Python-3776AB.svg?style=flat&logo=Python&logoColor=white" alt="Python">
</p>
<br>

<details><summary>Table of Contents</summary>

- [📍 Overview](#-overview)
- [👾 Features](#-features)
- [📁 Project Structure](#-project-structure)
  - [📂 Project Index](#-project-index)
- [🚀 Getting Started](#-getting-started)
  - [☑️ Prerequisites](#-prerequisites)
  - [⚙️ Installation](#-installation)
  - [🤖 Usage](#🤖-usage)
  - [🧪 Testing](#🧪-testing)
- [📌 Project Roadmap](#-project-roadmap)
- [🔰 Contributing](#-contributing)
- [🎗 License](#-license)
- [🙌 Acknowledgments](#-acknowledgments)

</details>
<hr>

## 📍 Overview

<code>❯ ZenithAI is an intelligent virtual architect agent designed to provide fast and accurate access to consolidated HPE information. Using artificial intelligence, ZenithAI simplifies the complexity of HPE architecture, providing personalized support for architects to optimally improve their designs. </code>

---

## 👾 Features

<code>❯ AI agent for processing Quickspecks files. More upcoming. </code>

---

## 📁 Project Structure

```sh
└── Llama-Index/
    ├── Quickspecks/
    ├── RAG Agent Opt.py
    ├── chromadb_con_test.py
    ├── requirements.txt
    └── zenith_vector_db/
        ├── 1d4064e3-5e65-42f1-bf03-161fca40fe41
        └── chroma.sqlite3
```


### 📂 Project Index
<details open>
	<summary><b><code>LLAMA-INDEX/</code></b></summary>
	<details> <!-- __root__ Submodule -->
		<summary><b>__root__</b></summary>
		<blockquote>
			<table>
			<tr>
				<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/RAG Agent Opt.py'>RAG Agent Opt.py</a></b></td>
				<td><code>❯ Main agent code</code></td>
			</tr>
			<tr>
				<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/chromadb_con_test.py'>chromadb_con_test.py</a></b></td>
				<td><code>❯ Test connection to check Chromadb</code></td>
			</tr>
			<tr>
				<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/requirements.txt'>requirements.txt</a></b></td>
				<td><code>❯ Python libraries required</code></td>
			</tr>
			</table>
		</blockquote>
	</details>
	<details> <!-- zenith_vector_db Submodule -->
		<summary><b>zenith_vector_db</b></summary>
		<blockquote>
			<table>
			<tr>
				<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/zenith_vector_db/chroma.sqlite3'>chroma.sqlite3</a></b></td>
				<td><code>❯ Vector Database</code></td>
			</tr>
			</table>
			<details>
				<summary><b>1d4064e3-5e65-42f1-bf03-161fca40fe41</b></summary>
				<blockquote>
					<table>
					<tr>
						<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/zenith_vector_db/1d4064e3-5e65-42f1-bf03-161fca40fe41/header.bin'>header.bin</a></b></td>
						<td><code>❯ REPLACE-ME</code></td>
					</tr>
					<tr>
						<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/zenith_vector_db/1d4064e3-5e65-42f1-bf03-161fca40fe41/length.bin'>length.bin</a></b></td>
						<td><code>❯ REPLACE-ME</code></td>
					</tr>
					<tr>
						<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/zenith_vector_db/1d4064e3-5e65-42f1-bf03-161fca40fe41/data_level0.bin'>data_level0.bin</a></b></td>
						<td><code>❯ REPLACE-ME</code></td>
					</tr>
					<tr>
						<td><b><a href='https://github.com/heinerhardt/Llama-Index/blob/master/zenith_vector_db/1d4064e3-5e65-42f1-bf03-161fca40fe41/link_lists.bin'>link_lists.bin</a></b></td>
						<td><code>❯ REPLACE-ME</code></td>
					</tr>
					</table>
				</blockquote>
			</details>
		</blockquote>
	</details>
</details>

---
## 🚀 Getting Started

### ☑️ Prerequisites

Before getting started with Llama-Index, ensure your runtime environment meets the following requirements:

- **Programming Language:** Python
- **Package Manager:** Pip


### ⚙️ Installation

Install Llama-Index using one of the following methods:

**Build from source:**

1. Clone the Llama-Index repository:
```sh
❯ git clone https://github.com/heinerhardt/Llama-Index
```

2. Navigate to the project directory:
```sh
❯ cd Llama-Index
```

3. Install the project dependencies:


**Using `pip`** &nbsp; [<img align="center" src="" />]()

```sh
❯ pip install requirements.txt
```




### 🤖 Usage
Run Llama-Index using the following command:
**Using `pip`** &nbsp; [<img align="center" src="" />]()

```sh
❯ python.exe "RAG Agent.py"
```


### 🧪 Testing
Today the agent works only with OPENAI LLM. You have to export your OPENAI API key first:
**Using `setx`** &nbsp; [<img align="center" src="" />]()

```sh
❯ setx OPENAI_API_KEY "your_openai_api_key"
```

While run, the agent will make you a question:
**Using `python`** &nbsp; [<img align="center" src="" />]()

```sh
❯ query = input("Please enter your question: ")
```

Upload new PDF to Quickspecks folder to get agent trained on data
**Using `cp`** &nbsp; [<img align="center" src="" />]()

```sh
❯ cp your_PDF.pdf /Quickspecks
```

---
## 📌 Project Roadmap

- [X] **`Task 1`**: <strike>First release: Only consults HPE Quickspecs</strike>
- [ ] **`Task 2`**: Consult HPE Seismic
- [ ] **`Task 3`**: WEB UI development.

---

## 🔰 Contributing

- **💬 [Join the Discussions](https://github.com/heinerhardt/Llama-Index/discussions)**: Share your insights, provide feedback, or ask questions.
- **🐛 [Report Issues](https://github.com/heinerhardt/Llama-Index/issues)**: Submit bugs found or log feature requests for the `Llama-Index` project.
- **💡 [Submit Pull Requests](https://github.com/heinerhardt/Llama-Index/blob/main/CONTRIBUTING.md)**: Review open PRs, and submit your own PRs.

<details closed>
<summary>Contributing Guidelines</summary>

1. **Fork the Repository**: Start by forking the project repository to your github account.
2. **Clone Locally**: Clone the forked repository to your local machine using a git client.
   ```sh
   git clone https://github.com/heinerhardt/Llama-Index
   ```
3. **Create a New Branch**: Always work on a new branch, giving it a descriptive name.
   ```sh
   git checkout -b new-feature-x
   ```
4. **Make Your Changes**: Develop and test your changes locally.
5. **Commit Your Changes**: Commit with a clear message describing your updates.
   ```sh
   git commit -m 'Implemented new feature x.'
   ```
6. **Push to github**: Push the changes to your forked repository.
   ```sh
   git push origin new-feature-x
   ```
7. **Submit a Pull Request**: Create a PR against the original project repository. Clearly describe the changes and their motivations.
8. **Review**: Once your PR is reviewed and approved, it will be merged into the main branch. Congratulations on your contribution!
</details>

<details closed>
<summary>Contributor Graph</summary>
<br>
<p align="left">
   <a href="https://github.com{/heinerhardt/Llama-Index/}graphs/contributors">
      <img src="https://contrib.rocks/image?repo=heinerhardt/Llama-Index">
   </a>
</p>
</details>

---

## 🎗 License

This project is protected under the Sercompe License. For more details, refer to the [LICENSE](https://choosealicense.com/licenses/) file.

---

## 🙌 Acknowledgments

- List any resources, contributors, inspiration, etc. here.

---
